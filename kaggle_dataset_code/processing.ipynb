{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_uXM_XXseher",
    "outputId": "78b1f125-ca94-479f-8cdd-0981a2b54234"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from string import punctuation\n",
    "import torch.optim as optim\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "y6Q9annxehfK",
    "outputId": "a837050b-dada-4726-c04e-617ab4e1c52e"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/fake-news/train.csv')\n",
    "test = pd.read_csv('../data/fake-news/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        3668\n",
       "title     3668\n",
       "author    3668\n",
       "text      3668\n",
       "label     3668\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid = train[int(0.8*len(train)):].copy()\n",
    "valid.dropna(inplace=True)\n",
    "valid.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        14617\n",
       "title     14617\n",
       "author    14617\n",
       "text      14617\n",
       "label     14617\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train[:int(0.8*len(train))].copy()\n",
    "train.dropna(inplace=True)\n",
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mbSdOa08ehfW",
    "outputId": "41d374ad-6eec-4068-cd57-e7e4b0bec386"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        4575\n",
       "title     4575\n",
       "author    4575\n",
       "text      4575\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.dropna(inplace=True)\n",
    "test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OnmWz91Zehfa",
    "outputId": "391d0c6a-2359-405d-ce11-d7cba5ef8f51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real news count\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id        8319\n",
       "title     8319\n",
       "author    8319\n",
       "text      8319\n",
       "label     8319\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('real news count')\n",
    "train[train['label']==0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2QUwOWvTehfl",
    "outputId": "8169e19d-bd42-45c0-99ae-3397fa27bf18"
   },
   "outputs": [],
   "source": [
    "stopWords = stopwords.words('english')\n",
    "\n",
    "def preprocessing(raw_text):\n",
    "    texts = [''.join([c for c in text.lower() if c not in punctuation]) for text in raw_text]\n",
    "    texts = ''.join(texts)\n",
    "    texts = [''.join([c for c in text.lower() if c not in 'â€™']) for text in texts]\n",
    "    texts = ''.join(texts)\n",
    "    texts = [word for word in word_tokenize(texts) if word not in stopWords]\n",
    "    texts = ' '.join(texts)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "317ee42e",
   "metadata": {
    "id": "317ee42e"
   },
   "outputs": [],
   "source": [
    "def getTokens(text):\n",
    "    tokenized_list = []\n",
    "    for txt in text:\n",
    "        tokenized = sent_tokenize(txt)\n",
    "        for i in tokenized:\n",
    "            wordsList = nltk.word_tokenize(i)\n",
    "            wordsList = [w.lower() for w in wordsList] \n",
    "            tokenized_list.append(wordsList)\n",
    "    return tokenized_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "458f1d53",
   "metadata": {
    "id": "458f1d53"
   },
   "outputs": [],
   "source": [
    "def getVocab(text, vocab):\n",
    "    for txt in text:\n",
    "        for w in txt:\n",
    "            vocab.add(w)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a009fb33",
   "metadata": {
    "id": "a009fb33"
   },
   "outputs": [],
   "source": [
    "def wordVec(text, vocab):\n",
    "    word_dict = {}\n",
    "    ind = 0\n",
    "    for word in vocab:\n",
    "        word_dict[word] = ind\n",
    "        ind += 1\n",
    "    word_vector = []\n",
    "    for txt in text:\n",
    "        w_vec = []\n",
    "        for word in txt:\n",
    "            w_vec.append(word_dict[word])\n",
    "        word_vector.append(w_vec)\n",
    "    return word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(seq, maxlen=80):\n",
    "    final = []\n",
    "    for lis in seq:\n",
    "#         print(lis, '\\n***\\n')\n",
    "        # padding\n",
    "        if len(lis)<maxlen:\n",
    "            pad = []\n",
    "            for i in range(maxlen-len(lis)):\n",
    "                if type(lis[0]) == int:\n",
    "                    pad.append(0)\n",
    "                else:\n",
    "                    pad.append([0 for i in range(len(lis[0]))])\n",
    "            for i in range(len(lis)):\n",
    "                pad.append(lis[i])\n",
    "            final.append(pad)\n",
    "        #truncating\n",
    "        else:\n",
    "            trunc = []\n",
    "            for i in range(maxlen):\n",
    "                trunc.append(lis[i])\n",
    "            final.append(trunc)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['title'] = train['title'].apply(preprocessing)\n",
    "train['title'] = train['title'].astype(str)\n",
    "\n",
    "test['title'] = test['title'].apply(preprocessing)\n",
    "test['title'] = test['title'].astype(str)\n",
    "\n",
    "valid['title'] = valid['title'].apply(preprocessing)\n",
    "valid['title'] = valid['title'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_title = np.array(train['title'])\n",
    "test_title = np.array(test['title'])\n",
    "valid_title = np.array(valid['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14617.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60.230622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19.146751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>61.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>361.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  14617.000000\n",
       "mean      60.230622\n",
       "std       19.146751\n",
       "min        0.000000\n",
       "25%       49.000000\n",
       "50%       61.000000\n",
       "75%       72.000000\n",
       "max      361.000000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = [len(train_title[i]) for i in range(len(train_title))]\n",
    "pd.DataFrame(count).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8f0144a",
   "metadata": {
    "id": "b8f0144a"
   },
   "outputs": [],
   "source": [
    "train_tokens = getTokens(train_title)\n",
    "test_tokens = getTokens(test_title)\n",
    "valid_tokens = getTokens(valid_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "af076565",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "af076565",
    "outputId": "e0796a97-05b8-488a-ed40-8e2a2b9b45e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25248"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get vocab\n",
    "\n",
    "vocab = set()\n",
    "vocab = getVocab(train_tokens, vocab)\n",
    "vocab = getVocab(test_tokens, vocab)\n",
    "vocab = getVocab(valid_tokens, vocab)\n",
    "vocab = list(vocab)\n",
    "vocab.sort()\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8a1430f2",
   "metadata": {
    "id": "8a1430f2"
   },
   "outputs": [],
   "source": [
    "# words\n",
    "\n",
    "## convert to vectors \n",
    "\n",
    "word_seq_train = wordVec(train_tokens, vocab)\n",
    "word_seq_test = wordVec(test_tokens, vocab)\n",
    "word_seq_valid = wordVec(valid_tokens, vocab)\n",
    "\n",
    "## padding\n",
    "\n",
    "word_seq_train = np.array(padding(word_seq_train), dtype='float32')\n",
    "word_seq_test = np.array(padding(word_seq_test), dtype='float32')\n",
    "word_seq_valid = np.array(padding(word_seq_valid), dtype='float32')\n",
    "\n",
    "## saving as csv\n",
    "\n",
    "pd.DataFrame(word_seq_train).to_csv('../data/fake-news/seq_data/word_seq_train.csv', index=False)\n",
    "pd.DataFrame(word_seq_test).to_csv('../data/fake-news//seq_data/word_seq_test.csv', index=False)\n",
    "pd.DataFrame(word_seq_valid).to_csv('../data/fake-news//seq_data/word_seq_valid.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
