{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "processing-liar.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "H9TWuOSvjkPk",
        "bRCrS5wZjkPr",
        "wuRghTlQOvas"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uXM_XXseher",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cee64eb-7ee2-491f-8b21-e7727a19a2db"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from string import punctuation\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SluPttC3joDL",
        "outputId": "6b20cc2a-4f8e-4930-ab99-1d38d6170c9c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmRP_gd9jvQD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ef12e61-7c89-48cc-fc05-cb0cecdfe5f1"
      },
      "source": [
        "cd drive/MyDrive"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tyb2Au0_yp0M"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QUwOWvTehfl"
      },
      "source": [
        "stopWords = stopwords.words('english')\n",
        "\n",
        "def preprocessing(raw_text):\n",
        "    # print(raw_text)\n",
        "    tokenized = []\n",
        "\n",
        "    \n",
        "    for sent in raw_text: \n",
        "        if type(sent) is str:\n",
        "          texts = [''.join([c for c in text.lower() if c not in punctuation]) for text in sent]\n",
        "          texts = ''.join(texts)\n",
        "          texts = [''.join([c for c in text.lower() if c not in '’']) for text in texts]\n",
        "          texts = ''.join(texts)\n",
        "          texts = [''.join([c for c in text.lower() if c not in '‘']) for text in texts]\n",
        "          texts = ''.join(texts)\n",
        "          texts = [word for word in word_tokenize(texts)] # if word not in stopWords]\n",
        "          # print(texts)\n",
        "          tokenized.append(texts)\n",
        "    # texts = ' '.join(texts)\n",
        "    # print(texts)\n",
        "    return tokenized"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "458f1d53"
      },
      "source": [
        "def getVocab(text, vocab):\n",
        "    for txt in text:\n",
        "        for w in txt:\n",
        "            vocab.add(w)\n",
        "    return vocab"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a009fb33"
      },
      "source": [
        "def wordVec(text, vocab):\n",
        "    word_dict = {}\n",
        "    ind = 0\n",
        "    for word in vocab:\n",
        "        word_dict[word] = ind\n",
        "        ind += 1\n",
        "    word_vector = []\n",
        "    for txt in text:\n",
        "        w_vec = []\n",
        "        for word in txt:\n",
        "            w_vec.append(word_dict[word])\n",
        "        word_vector.append(w_vec)\n",
        "    return word_vector"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j1zYFV40cm5"
      },
      "source": [
        "def wordVecMetaData(text, vocab):\n",
        "    word_dict = {}\n",
        "    ind = 0\n",
        "    for word in vocab:\n",
        "        word_dict[word] = ind\n",
        "        ind += 1\n",
        "    word_vector = []\n",
        "    for txt in text:\n",
        "        word_vector.append(word_dict[txt[0]])\n",
        "    return word_vector"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_s22t55jkPk"
      },
      "source": [
        "def padding(seq, maxlen):\n",
        "    final = []\n",
        "    for lis in seq:\n",
        "#         print(lis, '\\n***\\n')\n",
        "        # padding\n",
        "        if len(lis)<maxlen:\n",
        "            pad = []\n",
        "            # print(lis)\n",
        "            for i in range(maxlen-len(lis)):\n",
        "                if type(lis[0]) == int:\n",
        "                    pad.append(0)\n",
        "                else:\n",
        "                    pad.append([0 for i in range(len(lis[0]))])\n",
        "            for i in range(len(lis)):\n",
        "                pad.append(lis[i])\n",
        "            final.append(pad)\n",
        "        #truncating\n",
        "        else:\n",
        "            trunc = []\n",
        "            for i in range(maxlen):\n",
        "                trunc.append(lis[i])\n",
        "            final.append(trunc)\n",
        "    return final"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJScb4--jhWZ"
      },
      "source": [
        "def remove_nan(word_seq, data, threshold=0.8):\n",
        "  df = pd.DataFrame(word_seq)\n",
        "  cosine_corr = cosine_similarity(df, df)\n",
        "  for i in range(len(cosine_corr)):\n",
        "    cosine_corr[i][i] = -1\n",
        "  idx_cosine_similarity = np.argmax(cosine_corr, axis=1)\n",
        "  \n",
        "  # modify job title\n",
        "  index_nan = data[data['job title'].isna()].index\n",
        "  for i in index_nan:\n",
        "    if cosine_corr[i][idx_cosine_similarity[i]]>threshold:\n",
        "      data.at[i,'job title'] = data['job title'][idx_cosine_similarity[i]]\n",
        "    \n",
        "  # modify state info\n",
        "  index_nan = data[data['state info'].isna()].index\n",
        "  for i in index_nan: \n",
        "    if cosine_corr[i][idx_cosine_similarity[i]]>threshold:\n",
        "      data.at[i,'state info'] = data['state info'][idx_cosine_similarity[i]]\n",
        "    \n",
        "  idx = set()\n",
        "  temp_idx1 = data[data['job title'].isna()].index\n",
        "  temp_idx2 = data[data['state info'].isna()].index\n",
        "  idx.update(temp_idx1)\n",
        "  idx.update(temp_idx2)\n",
        "  \n",
        "  data.dropna(inplace=True)\n",
        "  data = data.reset_index(drop=True)\n",
        "  \n",
        "  return data, np.delete(word_seq,list(idx),0)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyKKlWLgl99N"
      },
      "source": [
        "columns = ['id','label','text','subject','speaker','job title','state info','party','barely true','false','half true','mostly true','pants on fire','context']\n",
        "label_map = {'pants-fire':-3, 'false':-2, 'barely-true':-1, 'half-true':1, 'mostly-true':3, 'true':3}"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zJQSMoivRMj"
      },
      "source": [
        "# Original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6Q9annxehfK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55dae33b-8f18-4ce7-b735-f7281cc4dcdc"
      },
      "source": [
        "train = pd.read_csv('liar/raw_data/liar/train.tsv',sep='\\t',header=None, names=columns)\n",
        "# print(len(train))#,train.isna().sum())\n",
        "# train.dropna(inplace=True)\n",
        "train['label'] = train['label'].map(label_map)\n",
        "train.drop(index=train[train.subject.isna()].index, inplace=True)\n",
        "train.drop(index=train[train.speaker.isna()].index, inplace=True)\n",
        "train.drop(index=train[train.text==' '].index, inplace=True)\n",
        "train.drop(index=train[train.text=='  '].index, inplace=True)\n",
        "train.drop(index=train[train.text=='\\n'].index, inplace=True)\n",
        "train.drop(columns=['context'],inplace=True)\n",
        "train = train.reset_index()\n",
        "train.count()"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "index            10238\n",
              "id               10238\n",
              "label            10238\n",
              "text             10238\n",
              "subject          10238\n",
              "speaker          10238\n",
              "job title         7343\n",
              "state info        8032\n",
              "party            10238\n",
              "barely true      10238\n",
              "false            10238\n",
              "half true        10238\n",
              "mostly true      10238\n",
              "pants on fire    10238\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j-zMBwtjkPf",
        "outputId": "0c40d882-6628-4bfe-f6e5-1aa1921da69e"
      },
      "source": [
        "valid = pd.read_csv('liar/raw_data/liar/valid.tsv',sep='\\t',header=None, names=columns)\n",
        "# print(len(valid))\n",
        "valid['label'] = valid['label'].map(label_map)\n",
        "# valid.dropna(inplace=True)\n",
        "valid.drop(index=valid[valid.subject.isna()].index, inplace=True)\n",
        "valid.drop(index=valid[valid.speaker.isna()].index, inplace=True)\n",
        "valid.drop(index=valid[valid.text==' '].index, inplace=True)\n",
        "valid.drop(index=valid[valid.text=='  '].index, inplace=True)\n",
        "valid.drop(index=valid[valid.text=='\\n'].index, inplace=True)\n",
        "valid.drop(columns=['context'],inplace=True)\n",
        "valid.count()"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id               1284\n",
              "label            1284\n",
              "text             1284\n",
              "subject          1284\n",
              "speaker          1284\n",
              "job title         939\n",
              "state info       1005\n",
              "party            1284\n",
              "barely true      1284\n",
              "false            1284\n",
              "half true        1284\n",
              "mostly true      1284\n",
              "pants on fire    1284\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giQAJj3BjkPg",
        "outputId": "ad507edb-d6cd-4743-84ce-946284a5a92a"
      },
      "source": [
        "test = pd.read_csv('liar/raw_data/liar/test.tsv',sep='\\t',header=None, names=columns)\n",
        "# print(len(test))\n",
        "test['label'] = test['label'].map(label_map)\n",
        "# test.dropna(inplace=True)\n",
        "test.drop(index=test[test.subject.isna()].index, inplace=True)\n",
        "test.drop(index=test[test.speaker.isna()].index, inplace=True)\n",
        "test.drop(index=test[test.text==' '].index, inplace=True)\n",
        "test.drop(index=test[test.text=='  '].index, inplace=True)\n",
        "test.drop(index=test[test.text=='\\n'].index, inplace=True)\n",
        "test.drop(columns=['context'],inplace=True)\n",
        "test.count()"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id               1267\n",
              "label            1267\n",
              "text             1267\n",
              "subject          1267\n",
              "speaker          1267\n",
              "job title         942\n",
              "state info       1005\n",
              "party            1267\n",
              "barely true      1267\n",
              "false            1267\n",
              "half true        1267\n",
              "mostly true      1267\n",
              "pants on fire    1267\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnmWz91Zehfa",
        "outputId": "5f897caf-412c-46e3-b1d2-96871dbe82c4"
      },
      "source": [
        "print('real news count')\n",
        "train[train['label']>0].count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "real news count\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "index            5752\n",
              "id               5752\n",
              "label            5752\n",
              "text             5752\n",
              "subject          5752\n",
              "speaker          5752\n",
              "job title        4264\n",
              "state info       4663\n",
              "party            5752\n",
              "barely true      5752\n",
              "false            5752\n",
              "half true        5752\n",
              "mostly true      5752\n",
              "pants on fire    5752\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9TWuOSvjkPk"
      },
      "source": [
        "# text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFEkPkq8jkPl"
      },
      "source": [
        "train_text = np.array(train['text'])\n",
        "test_text = np.array(test['text'])\n",
        "valid_text = np.array(valid['text'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8f0144a"
      },
      "source": [
        "train_tokens = preprocessing(train_text)\n",
        "test_tokens = preprocessing(test_text)\n",
        "valid_tokens = preprocessing(valid_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "0oNii2H8jkPm",
        "outputId": "a7f0834e-8326-48b9-8dcf-9856ee275ebb"
      },
      "source": [
        "count = [len(train_tokens[i]) for i in range(len(train_tokens))]\n",
        "pd.DataFrame(count).describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10238.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>17.935827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.581478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>12.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>17.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>22.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>464.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0\n",
              "count  10238.000000\n",
              "mean      17.935827\n",
              "std        9.581478\n",
              "min        2.000000\n",
              "25%       12.000000\n",
              "50%       17.000000\n",
              "75%       22.000000\n",
              "max      464.000000"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af076565",
        "outputId": "89a6c6a1-cd6a-42b1-8262-c1b0f4340522"
      },
      "source": [
        "## get vocab\n",
        "\n",
        "vocab = set()\n",
        "vocab = getVocab(train_tokens, vocab)\n",
        "vocab = getVocab(test_tokens, vocab)\n",
        "vocab = getVocab(valid_tokens, vocab)\n",
        "vocab = list(vocab)\n",
        "vocab.sort()\n",
        "len(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14957"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IOdcoTXjLj6"
      },
      "source": [
        "# words\n",
        "## convert to vectors \n",
        "word_seq_train = wordVec(train_tokens, vocab)\n",
        "word_seq_test = wordVec(test_tokens, vocab)\n",
        "word_seq_valid = wordVec(valid_tokens, vocab)\n",
        "\n",
        "## padding\n",
        "word_seq_train = np.array(padding(word_seq_train, maxlen=50), dtype='float32')\n",
        "word_seq_test = np.array(padding(word_seq_test, maxlen=50), dtype='float32')\n",
        "word_seq_valid = np.array(padding(word_seq_valid, maxlen=50), dtype='float32')\n",
        "\n",
        "threshold=0.8\n",
        "# replace nan values in stateinfo, job title with the values from most similar text\n",
        "train, word_seq_train = remove_nan(word_seq_train, train, threshold)\n",
        "test, word_seq_test = remove_nan(word_seq_test, test, threshold)\n",
        "valid, word_seq_valid = remove_nan(word_seq_valid, valid, threshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2rXDM4zlvSt"
      },
      "source": [
        "# ## saving as csv\n",
        "pd.DataFrame(word_seq_train).to_csv('liar/text_seq_data/word_seq_train.csv', index=False)\n",
        "pd.DataFrame(word_seq_test).to_csv('liar/text_seq_data/word_seq_test.csv', index=False)\n",
        "pd.DataFrame(word_seq_valid).to_csv('liar/text_seq_data/word_seq_valid.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRCrS5wZjkPr"
      },
      "source": [
        "# label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GGB28JDjkPr"
      },
      "source": [
        "train_label = np.array(train.label)\n",
        "test_label = np.array(test.label)\n",
        "valid_label = np.array(valid.label)\n",
        "\n",
        "pd.DataFrame(train_label,columns=['label']).to_csv('liar/label_seq_data/train_label.csv', index=False)\n",
        "pd.DataFrame(test_label,columns=['label']).to_csv('liar/label_seq_data/test_label.csv', index=False)\n",
        "pd.DataFrame(valid_label,columns=['label']).to_csv('liar/label_seq_data/valid_label.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuRghTlQOvas"
      },
      "source": [
        "# meta data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbU84vAtziVx"
      },
      "source": [
        "columns = train.columns\n",
        "columns = columns.drop(['label','text'])\n",
        "train_meta = np.array(train[columns])\n",
        "pd.DataFrame(train_meta,columns=columns).to_csv('liar/meta_data/train_meta.csv', index=False)\n",
        "\n",
        "columns = test.columns\n",
        "columns = columns.drop(['label','text'])\n",
        "test_meta = np.array(test[columns])\n",
        "pd.DataFrame(test_meta,columns=columns).to_csv('liar/meta_data/test_meta.csv', index=False)\n",
        "\n",
        "columns = valid.columns\n",
        "columns = columns.drop(['label','text'])\n",
        "valid_meta = np.array(valid[columns])\n",
        "pd.DataFrame(valid_meta,columns=columns).to_csv('liar/meta_data/valid_meta.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gge6-PVr1nr1"
      },
      "source": [
        "# party"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0c1nntq1lae"
      },
      "source": [
        "train_party = np.array(train['party'])\n",
        "test_party = np.array(test['party'])\n",
        "valid_party = np.array(valid['party'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OLZ12ej1laf"
      },
      "source": [
        "train_tokens = preprocessing(train_party)\n",
        "test_tokens = preprocessing(test_party)\n",
        "valid_tokens = preprocessing(valid_party)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "dY3hU5Qq1laf",
        "outputId": "cc9eb572-c7d6-4962-f0ee-919eb50e53ee"
      },
      "source": [
        "count = [len(train_tokens[i]) for i in range(len(train_tokens))]\n",
        "pd.DataFrame(count).describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>9465.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            0\n",
              "count  9465.0\n",
              "mean      1.0\n",
              "std       0.0\n",
              "min       1.0\n",
              "25%       1.0\n",
              "50%       1.0\n",
              "75%       1.0\n",
              "max       1.0"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2btETzeb1lag",
        "outputId": "62179ebe-4d70-41c8-ba63-7173d0a98f61"
      },
      "source": [
        "## get vocab\n",
        "vocab = set()\n",
        "vocab = getVocab(train_tokens, vocab)\n",
        "vocab = getVocab(test_tokens, vocab)\n",
        "vocab = getVocab(valid_tokens, vocab)\n",
        "vocab = list(vocab)\n",
        "vocab.sort()\n",
        "len(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bybz1w291lah"
      },
      "source": [
        "# words\n",
        "## convert to vectors \n",
        "party_seq_train = wordVecMetaData(train_tokens, vocab)\n",
        "party_seq_test = wordVecMetaData(test_tokens, vocab)\n",
        "party_seq_valid = wordVecMetaData(valid_tokens, vocab)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y14S539W1lah"
      },
      "source": [
        "# ## saving as csv\n",
        "pd.DataFrame(party_seq_train,columns=['party']).to_csv('liar/party_data/train_party.csv', index=False)\n",
        "pd.DataFrame(party_seq_test,columns=['party']).to_csv('liar/party_data/test_party.csv', index=False)\n",
        "pd.DataFrame(party_seq_valid,columns=['party']).to_csv('liar/party_data/valid_party.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G7-T_IVZtOR"
      },
      "source": [
        "# speaker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AhJzTrNZtOS"
      },
      "source": [
        "train_speaker = np.array(train['speaker'])\n",
        "test_speaker = np.array(test['speaker'])\n",
        "valid_speaker = np.array(valid['speaker'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpWZphWpZtOS"
      },
      "source": [
        "train_tokens = preprocessing(train_speaker)\n",
        "test_tokens = preprocessing(test_speaker)\n",
        "valid_tokens = preprocessing(valid_speaker)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "gL0Q1S5zZtOS",
        "outputId": "2deffa48-f650-4e4e-bebb-5ff43e20caa7"
      },
      "source": [
        "count = [len(train_tokens[i]) for i in range(len(train_tokens))]\n",
        "pd.DataFrame(count).describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>9465.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            0\n",
              "count  9465.0\n",
              "mean      1.0\n",
              "std       0.0\n",
              "min       1.0\n",
              "25%       1.0\n",
              "50%       1.0\n",
              "75%       1.0\n",
              "max       1.0"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tdpQOVoZtOT",
        "outputId": "e0f34934-32b9-4ed4-e8ca-64ee2a9421a9"
      },
      "source": [
        "## get vocab\n",
        "vocab = set()\n",
        "vocab = getVocab(train_tokens, vocab)\n",
        "vocab = getVocab(test_tokens, vocab)\n",
        "vocab = getVocab(valid_tokens, vocab)\n",
        "vocab = list(vocab)\n",
        "vocab.sort()\n",
        "len(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3066"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3awOyHlZtOT"
      },
      "source": [
        "# words\n",
        "## convert to vectors \n",
        "speaker_seq_train = wordVecMetaData(train_tokens, vocab)\n",
        "speaker_seq_test = wordVecMetaData(test_tokens, vocab)\n",
        "speaker_seq_valid = wordVecMetaData(valid_tokens, vocab)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5fhuSFOZtOT"
      },
      "source": [
        "# ## saving as csv\n",
        "pd.DataFrame(speaker_seq_train,columns=['speaker']).to_csv('liar/speaker_data/train_speaker.csv', index=False)\n",
        "pd.DataFrame(speaker_seq_test,columns=['speaker']).to_csv('liar/speaker_data/test_speaker.csv', index=False)\n",
        "pd.DataFrame(speaker_seq_valid,columns=['speaker']).to_csv('liar/speaker_data/valid_speaker.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3y2XSeOe6LIt"
      },
      "source": [
        "# state info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1dLPFem6J6P"
      },
      "source": [
        "train_party = np.array(train['state info'])\n",
        "test_party = np.array(test['state info'])\n",
        "valid_party = np.array(valid['state info'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSNIGzk26Oa3"
      },
      "source": [
        "train_tokens = preprocessing(train_party)\n",
        "test_tokens = preprocessing(test_party)\n",
        "valid_tokens = preprocessing(valid_party)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "U2EfMKW_6Oa3",
        "outputId": "88fdecc4-aba0-4a92-fb33-57f243e449d0"
      },
      "source": [
        "count = [len(train_tokens[i]) for i in range(len(train_tokens))]\n",
        "pd.DataFrame(count).describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>9465.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.208135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.414495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0\n",
              "count  9465.000000\n",
              "mean      1.208135\n",
              "std       0.414495\n",
              "min       1.000000\n",
              "25%       1.000000\n",
              "50%       1.000000\n",
              "75%       1.000000\n",
              "max       7.000000"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7goNdEmf6Oa3",
        "outputId": "62179ebe-4d70-41c8-ba63-7173d0a98f61"
      },
      "source": [
        "## get vocab\n",
        "vocab = set()\n",
        "vocab = getVocab(train_tokens, vocab)\n",
        "vocab = getVocab(test_tokens, vocab)\n",
        "vocab = getVocab(valid_tokens, vocab)\n",
        "vocab = list(vocab)\n",
        "vocab.sort()\n",
        "len(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3C6BrW76Oa4"
      },
      "source": [
        "# words\n",
        "## convert to vectors \n",
        "state_seq_train = wordVecMetaData(train_tokens, vocab)\n",
        "state_seq_test = wordVecMetaData(test_tokens, vocab)\n",
        "state_seq_valid = wordVecMetaData(valid_tokens, vocab)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2V5bIb76Oa4"
      },
      "source": [
        "# ## saving as csv\n",
        "pd.DataFrame(state_seq_train,columns=['state_info']).to_csv('liar/state_info_data/train_state_info.csv', index=False)\n",
        "pd.DataFrame(state_seq_test,columns=['state_info']).to_csv('liar/state_info_data/test_state_info.csv', index=False)\n",
        "pd.DataFrame(state_seq_valid,columns=['state_info']).to_csv('liar/state_info_data/valid_state_info.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIWOKbaRZX_8"
      },
      "source": [
        "# Feature Correlation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYbJpmyiQZos"
      },
      "source": [
        "def pearsonr_2D(x, y,y_is_oneD=False):\n",
        "    \"\"\"computes pearson correlation coefficient\n",
        "       where x is a 1D and y a 2D array\"\"\"\n",
        "       \n",
        "    if y_is_oneD:\n",
        "      upper = np.sum((x - np.mean(x)) * (y - np.mean(y)))\n",
        "      lower = np.sqrt(np.sum(np.power(x - np.mean(x), 2)) * np.sum(np.power(y - np.mean(y), 2)))\n",
        "      rho = upper / lower\n",
        "    else:\n",
        "      upper = np.sum((x - np.mean(x)) * (y - np.mean(y, axis=1)[:,None]), axis=1)\n",
        "      lower = np.sqrt(np.sum(np.power(x - np.mean(x), 2)) * np.sum(np.power(y - np.mean(y, axis=1)[:,None], 2), axis=1))\n",
        "      rho = upper / lower\n",
        "    \n",
        "    return rho"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cy2xZLOOevL"
      },
      "source": [
        "valid = pd.read_csv('liar/text_seq_data/word_seq_valid.csv')\n",
        "test = pd.read_csv('liar/text_seq_data/word_seq_test.csv')\n",
        "train = pd.read_csv('liar/text_seq_data/word_seq_train.csv')\n",
        "text = pd.concat([train,test,valid]).reset_index()\n",
        "text.drop(columns=['index'],inplace=True)\n",
        "\n",
        "valid = pd.read_csv('liar/party_data/valid_party.csv')\n",
        "test = pd.read_csv('liar/party_data/test_party.csv')\n",
        "train = pd.read_csv('liar/party_data/train_party.csv')\n",
        "party = pd.concat([train,test,valid]).reset_index()\n",
        "party.drop(columns=['index'],inplace=True)\n",
        "party=np.array(party)\n",
        "\n",
        "valid = pd.read_csv('liar/speaker_data/valid_speaker.csv')\n",
        "test = pd.read_csv('liar/speaker_data/test_speaker.csv')\n",
        "train = pd.read_csv('liar/speaker_data/train_speaker.csv')\n",
        "speaker = pd.concat([train,test,valid]).reset_index()\n",
        "speaker.drop(columns=['index'],inplace=True)\n",
        "speaker=np.array(speaker)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK-Jp0KyR8BN",
        "outputId": "8a67e31a-729f-4b21-d0ea-a67e6420b91a"
      },
      "source": [
        "np.mean(pearsonr_2D(speaker,text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.785396102952175e-20"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ctfe31R1XoSd",
        "outputId": "fd6d1908-ae48-43e7-b16a-98acf8b49eb3"
      },
      "source": [
        "np.mean(pearsonr_2D(party,text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.644268867895266e-20"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhl6sFngXpoN",
        "outputId": "46996db3-948b-4b68-ad17-a253f14e8360"
      },
      "source": [
        "pearsonr_2D(speaker,party,True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2105039637976894"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    }
  ]
}