{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uXM_XXseher",
        "outputId": "9c5641a5-5d02-4843-e5f9-2ee511726529"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from string import punctuation\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SluPttC3joDL",
        "outputId": "7de3ce0a-321e-4045-e095-434d3a4f684e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmRP_gd9jvQD",
        "outputId": "fd665769-f7e2-4c97-d1fe-f53681e9522f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "cd drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SyKKlWLgl99N"
      },
      "outputs": [],
      "source": [
        "columns = ['id','label','text','subject','speaker','job title','state info','party','barely true','false','half true','mostly true','pants on fire','context']\n",
        "label_map = {'pants-fire':-3, 'false':-2, 'barely-true':-1, 'half-true':1, 'mostly-true':2, 'true':3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6Q9annxehfK",
        "outputId": "4af962d4-c5f2-4732-afc2-3747d49f56e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "index            10238\n",
              "id               10238\n",
              "label            10238\n",
              "text             10238\n",
              "subject          10238\n",
              "speaker          10238\n",
              "job title         7343\n",
              "state info        8032\n",
              "party            10238\n",
              "barely true      10238\n",
              "false            10238\n",
              "half true        10238\n",
              "mostly true      10238\n",
              "pants on fire    10238\n",
              "dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = pd.read_csv('../data/liar_dataset/raw_data/train.tsv',sep='\\t',header=None, names=columns)\n",
        "# print(len(train))#,train.isna().sum())\n",
        "train['label'] = train['label'].map(label_map)\n",
        "train.drop(index=train[train.subject.isna()].index, inplace=True)\n",
        "train.drop(index=train[train.speaker.isna()].index, inplace=True)\n",
        "train.drop(index=train[train.text==' '].index, inplace=True)\n",
        "train.drop(index=train[train.text=='  '].index, inplace=True)\n",
        "train.drop(index=train[train.text=='\\n'].index, inplace=True)\n",
        "train.drop(columns=['context'],inplace=True)\n",
        "train = train.reset_index()\n",
        "train.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j-zMBwtjkPf",
        "outputId": "949f752a-8776-4766-d8e2-62c9d6cfaea9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1284\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "id               1284\n",
              "label            1284\n",
              "text             1284\n",
              "subject          1284\n",
              "speaker          1284\n",
              "job title         939\n",
              "state info       1005\n",
              "party            1284\n",
              "barely true      1284\n",
              "false            1284\n",
              "half true        1284\n",
              "mostly true      1284\n",
              "pants on fire    1284\n",
              "dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid = pd.read_csv('../data/liar_dataset/raw_data/valid.tsv',sep='\\t',header=None, names=columns)\n",
        "print(len(valid))\n",
        "valid['label'] = valid['label'].map(label_map)\n",
        "# valid.dropna(inplace=True)\n",
        "valid.drop(index=valid[valid.subject.isna()].index, inplace=True)\n",
        "valid.drop(index=valid[valid.speaker.isna()].index, inplace=True)\n",
        "valid.drop(index=valid[valid.text==' '].index, inplace=True)\n",
        "valid.drop(index=valid[valid.text=='  '].index, inplace=True)\n",
        "valid.drop(index=valid[valid.text=='\\n'].index, inplace=True)\n",
        "valid.drop(columns=['context'],inplace=True)\n",
        "valid.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giQAJj3BjkPg",
        "outputId": "421c1d8d-1cbb-4562-cf83-1e105f0a5b72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1267\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "id               1267\n",
              "label            1267\n",
              "text             1267\n",
              "subject          1267\n",
              "speaker          1267\n",
              "job title         942\n",
              "state info       1005\n",
              "party            1267\n",
              "barely true      1267\n",
              "false            1267\n",
              "half true        1267\n",
              "mostly true      1267\n",
              "pants on fire    1267\n",
              "dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = pd.read_csv('../data/liar_dataset/raw_data/test.tsv',sep='\\t',header=None, names=columns)\n",
        "print(len(test))\n",
        "test['label'] = test['label'].map(label_map)\n",
        "# valid.dropna(inplace=True)\n",
        "test.drop(index=test[test.subject.isna()].index, inplace=True)\n",
        "test.drop(index=test[test.speaker.isna()].index, inplace=True)\n",
        "test.drop(index=test[test.text==' '].index, inplace=True)\n",
        "test.drop(index=test[test.text=='  '].index, inplace=True)\n",
        "test.drop(index=test[test.text=='\\n'].index, inplace=True)\n",
        "test.drop(columns=['context'],inplace=True)\n",
        "test.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnmWz91Zehfa",
        "outputId": "fd325bfa-629d-47ff-b4eb-05712e2cb691"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "real news count\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "index            5752\n",
              "id               5752\n",
              "label            5752\n",
              "text             5752\n",
              "subject          5752\n",
              "speaker          5752\n",
              "job title        4264\n",
              "state info       4663\n",
              "party            5752\n",
              "barely true      5752\n",
              "false            5752\n",
              "half true        5752\n",
              "mostly true      5752\n",
              "pants on fire    5752\n",
              "dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('real news count')\n",
        "train[train['label']>0].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2QUwOWvTehfl"
      },
      "outputs": [],
      "source": [
        "stopWords = stopwords.words('english')\n",
        "\n",
        "def preprocessing(raw_text):\n",
        "    # print(raw_text)\n",
        "    tokenized = []\n",
        "    for sent in raw_text:\n",
        "        texts = [''.join([c for c in text.lower() if c not in punctuation]) for text in sent]\n",
        "        texts = ''.join(texts)\n",
        "        texts = [''.join([c for c in text.lower() if c not in '’']) for text in texts]\n",
        "        texts = ''.join(texts)\n",
        "        texts = [''.join([c for c in text.lower() if c not in '‘']) for text in texts]\n",
        "        texts = ''.join(texts)\n",
        "        texts = [word for word in word_tokenize(texts)] # if word not in stopWords]\n",
        "        # print(texts)\n",
        "        tokenized.append(texts)\n",
        "    # texts = ' '.join(texts)\n",
        "    # print(texts)\n",
        "    return tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "458f1d53"
      },
      "outputs": [],
      "source": [
        "def getVocab(text, vocab):\n",
        "    for txt in text:\n",
        "        for w in txt:\n",
        "            vocab.add(w)\n",
        "    return vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "a009fb33"
      },
      "outputs": [],
      "source": [
        "def wordVec(text, vocab):\n",
        "    word_dict = {}\n",
        "    ind = 0\n",
        "    for word in vocab:\n",
        "        word_dict[word] = ind\n",
        "        ind += 1\n",
        "    word_vector = []\n",
        "    for txt in text:\n",
        "        w_vec = []\n",
        "        for word in txt:\n",
        "            w_vec.append(word_dict[word])\n",
        "        word_vector.append(w_vec)\n",
        "    return word_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Y_s22t55jkPk"
      },
      "outputs": [],
      "source": [
        "def padding(seq, maxlen):\n",
        "    final = []\n",
        "    for lis in seq:\n",
        "#         print(lis, '\\n***\\n')\n",
        "        # padding\n",
        "        if len(lis)<maxlen:\n",
        "            pad = []\n",
        "            # print(lis)\n",
        "            for i in range(maxlen-len(lis)):\n",
        "                if type(lis[0]) == int:\n",
        "                    pad.append(0)\n",
        "                else:\n",
        "                    pad.append([0 for i in range(len(lis[0]))])\n",
        "            for i in range(len(lis)):\n",
        "                pad.append(lis[i])\n",
        "            final.append(pad)\n",
        "        #truncating\n",
        "        else:\n",
        "            trunc = []\n",
        "            for i in range(maxlen):\n",
        "                trunc.append(lis[i])\n",
        "            final.append(trunc)\n",
        "    return final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "cJScb4--jhWZ"
      },
      "outputs": [],
      "source": [
        "def remove_nan(word_seq, data, threshold=0.8):\n",
        "  df = pd.DataFrame(word_seq)\n",
        "  cosine_corr = cosine_similarity(df, df)\n",
        "  for i in range(len(cosine_corr)):\n",
        "    cosine_corr[i][i] = -1\n",
        "  idx_cosine_similarity = np.argmax(cosine_corr, axis=1)\n",
        "  \n",
        "  index_nan = data[data['job title'].isna()].index\n",
        "  for i in index_nan:\n",
        "    if cosine_corr[i][idx_cosine_similarity[i]]>threshold:\n",
        "      data.at[i,'job title'] = data['job title'][idx_cosine_similarity[i]]\n",
        "    \n",
        "  index_nan = data[data['state info'].isna()].index\n",
        "  for i in index_nan:\n",
        "    if cosine_corr[i][idx_cosine_similarity[i]]>threshold:\n",
        "      data.at[i,'state info'] = data['state info'][idx_cosine_similarity[i]]\n",
        "    \n",
        "  idx = set()\n",
        "  temp_idx1 = data[data['job title'].isna()].index\n",
        "  temp_idx2 = data[data['state info'].isna()].index\n",
        "  idx.update(temp_idx1)\n",
        "  idx.update(temp_idx2)\n",
        "  \n",
        "  # print(len(idx))\n",
        "  data.dropna(inplace=True)\n",
        "  data = data.reset_index(drop=True)\n",
        "  # print(data.count())\n",
        "  \n",
        "  return data, np.delete(word_seq,list(idx),0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9TWuOSvjkPk"
      },
      "source": [
        "# text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "iFEkPkq8jkPl"
      },
      "outputs": [],
      "source": [
        "train_text = np.array(train['text'])\n",
        "test_text = np.array(test['text'])\n",
        "valid_text = np.array(valid['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "b8f0144a"
      },
      "outputs": [],
      "source": [
        "train_tokens = preprocessing(train_text)\n",
        "test_tokens = preprocessing(test_text)\n",
        "valid_tokens = preprocessing(valid_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "0oNii2H8jkPm",
        "outputId": "94b89874-16e2-46a4-d960-3db9ad02993e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10238.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>17.935827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.581478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>12.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>17.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>22.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>464.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0\n",
              "count  10238.000000\n",
              "mean      17.935827\n",
              "std        9.581478\n",
              "min        2.000000\n",
              "25%       12.000000\n",
              "50%       17.000000\n",
              "75%       22.000000\n",
              "max      464.000000"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count = [len(train_tokens[i]) for i in range(len(train_tokens))]\n",
        "pd.DataFrame(count).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af076565",
        "outputId": "96f4ee4c-48b7-4b44-c841-d67931efe10e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14957"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## get vocab\n",
        "\n",
        "vocab = set()\n",
        "vocab = getVocab(train_tokens, vocab)\n",
        "vocab = getVocab(test_tokens, vocab)\n",
        "vocab = getVocab(valid_tokens, vocab)\n",
        "vocab = list(vocab)\n",
        "vocab.sort()\n",
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8a1430f2"
      },
      "outputs": [],
      "source": [
        "# words\n",
        "\n",
        "## convert to vectors \n",
        "word_seq_train = wordVec(train_tokens, vocab)\n",
        "word_seq_test = wordVec(test_tokens, vocab)\n",
        "word_seq_valid = wordVec(valid_tokens, vocab)\n",
        "\n",
        "## padding\n",
        "word_seq_train = np.array(padding(word_seq_train, maxlen=1200), dtype='float32')\n",
        "word_seq_test = np.array(padding(word_seq_test, maxlen=1200), dtype='float32')\n",
        "word_seq_valid = np.array(padding(word_seq_valid, maxlen=1200), dtype='float32')\n",
        "\n",
        "threshold=0.8\n",
        "# replace nan values in stateinfo, job title with the values from most similar text\n",
        "train, word_seq_train = remove_nan(word_seq_train, train, threshold)\n",
        "test, word_seq_test = remove_nan(word_seq_test, test, threshold)\n",
        "valid, word_seq_valid = remove_nan(word_seq_valid, valid, threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Q2rXDM4zlvSt"
      },
      "outputs": [],
      "source": [
        "## saving as csv\n",
        "pd.DataFrame(word_seq_train).to_csv('../data/liar_dataset/text_seq_data/word_seq_train.csv', index=False)\n",
        "pd.DataFrame(word_seq_test).to_csv('../data/liar_dataset/text_seq_data/word_seq_test.csv', index=False)\n",
        "pd.DataFrame(word_seq_valid).to_csv('../data/liar_dataset/text_seq_data/word_seq_valid.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRCrS5wZjkPr"
      },
      "source": [
        "# label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "3GGB28JDjkPr"
      },
      "outputs": [],
      "source": [
        "train_label = np.array(train.label)\n",
        "test_label = np.array(test.label)\n",
        "valid_label = np.array(valid.label)\n",
        "\n",
        "pd.DataFrame(train_label,columns=['label']).to_csv('../data/liar_dataset/label_seq_data/train_label.csv', index=False)\n",
        "pd.DataFrame(test_label,columns=['label']).to_csv('../data/liar_dataset/label_seq_data/test_label.csv', index=False)\n",
        "pd.DataFrame(valid_label,columns=['label']).to_csv('../data/liar_dataset/label_seq_data/valid_label.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuRghTlQOvas"
      },
      "source": [
        "# meta data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "mbU84vAtziVx"
      },
      "outputs": [],
      "source": [
        "columns = train.columns\n",
        "columns = columns.drop(['label','text'])\n",
        "train_meta = np.array(train[columns])\n",
        "pd.DataFrame(train_meta,columns=columns).to_csv('../data/liar_dataset/meta_data/train_meta.csv', index=False)\n",
        "\n",
        "columns = test.columns\n",
        "columns = columns.drop(['label','text'])\n",
        "test_meta = np.array(test[columns])\n",
        "pd.DataFrame(test_meta,columns=columns).to_csv('../data/liar_dataset/meta_data/test_meta.csv', index=False)\n",
        "\n",
        "columns = valid.columns\n",
        "columns = columns.drop(['label','text'])\n",
        "valid_meta = np.array(valid[columns])\n",
        "pd.DataFrame(valid_meta,columns=columns).to_csv('../data/liar_dataset/meta_data/valid_meta.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAoKHOeU2b6D"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "processing-liar.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
